{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import PyClass \n",
    "import PyClass2\n",
    "import PyClass3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_train = PyClass2.my_datset2(root='new_train',option='Mel_S_pca',option2 = 'new_train_label',train = True)\n",
    "                         \n",
    "\n",
    "sound_test = PyClass2.my_datset2(root='new_test',option='Mel_S_pca',option2 = 'new_test_label',train = False)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_loader  = DataLoader(dataset=sound_train,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False\n",
    "                                           ,num_workers=1)\n",
    "\n",
    "test_loader = DataLoader(dataset=sound_test,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                        num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 1, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "print(sound_train.train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "linear1 = torch.nn.Linear(1600, 512, bias = True)\n",
    "relu = torch.nn.ReLU()\n",
    "linear2 = torch.nn.Linear(512, 256, bias = True)\n",
    "relu2 = torch.nn.ReLU()\n",
    "linear3 = torch.nn.Linear(256,128,bias = True)\n",
    "relu3 = torch.nn.ReLU()\n",
    "linear4 = torch.nn.Linear(128,8,bias=True)\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, linear2,relu2 , linear3,relu3,linear4)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], lter [10/40], Loss: 2.0782\n",
      "Epoch [1/50], lter [20/40], Loss: 2.0946\n",
      "Epoch [1/50], lter [30/40], Loss: 2.0919\n",
      "Epoch [1/50], lter [40/40], Loss: 2.0853\n",
      "Epoch [2/50], lter [10/40], Loss: 2.0067\n",
      "Epoch [2/50], lter [20/40], Loss: 2.0277\n",
      "Epoch [2/50], lter [30/40], Loss: 2.0231\n",
      "Epoch [2/50], lter [40/40], Loss: 1.9981\n",
      "Epoch [3/50], lter [10/40], Loss: 1.9281\n",
      "Epoch [3/50], lter [20/40], Loss: 1.9409\n",
      "Epoch [3/50], lter [30/40], Loss: 1.9291\n",
      "Epoch [3/50], lter [40/40], Loss: 1.8678\n",
      "Epoch [4/50], lter [10/40], Loss: 1.7986\n",
      "Epoch [4/50], lter [20/40], Loss: 1.7810\n",
      "Epoch [4/50], lter [30/40], Loss: 1.7397\n",
      "Epoch [4/50], lter [40/40], Loss: 1.6374\n",
      "Epoch [5/50], lter [10/40], Loss: 1.5334\n",
      "Epoch [5/50], lter [20/40], Loss: 1.4666\n",
      "Epoch [5/50], lter [30/40], Loss: 1.3523\n",
      "Epoch [5/50], lter [40/40], Loss: 1.2118\n",
      "Epoch [6/50], lter [10/40], Loss: 1.0597\n",
      "Epoch [6/50], lter [20/40], Loss: 0.9511\n",
      "Epoch [6/50], lter [30/40], Loss: 0.8182\n",
      "Epoch [6/50], lter [40/40], Loss: 0.6766\n",
      "Epoch [7/50], lter [10/40], Loss: 0.5019\n",
      "Epoch [7/50], lter [20/40], Loss: 0.4540\n",
      "Epoch [7/50], lter [30/40], Loss: 0.4488\n",
      "Epoch [7/50], lter [40/40], Loss: 0.3482\n",
      "Epoch [8/50], lter [10/40], Loss: 0.1930\n",
      "Epoch [8/50], lter [20/40], Loss: 0.2059\n",
      "Epoch [8/50], lter [30/40], Loss: 0.2890\n",
      "Epoch [8/50], lter [40/40], Loss: 0.1900\n",
      "Epoch [9/50], lter [10/40], Loss: 0.0905\n",
      "Epoch [9/50], lter [20/40], Loss: 0.1050\n",
      "Epoch [9/50], lter [30/40], Loss: 0.2106\n",
      "Epoch [9/50], lter [40/40], Loss: 0.1023\n",
      "Epoch [10/50], lter [10/40], Loss: 0.0522\n",
      "Epoch [10/50], lter [20/40], Loss: 0.0581\n",
      "Epoch [10/50], lter [30/40], Loss: 0.1578\n",
      "Epoch [10/50], lter [40/40], Loss: 0.0578\n",
      "Epoch [11/50], lter [10/40], Loss: 0.0337\n",
      "Epoch [11/50], lter [20/40], Loss: 0.0373\n",
      "Epoch [11/50], lter [30/40], Loss: 0.1111\n",
      "Epoch [11/50], lter [40/40], Loss: 0.0381\n",
      "Epoch [12/50], lter [10/40], Loss: 0.0238\n",
      "Epoch [12/50], lter [20/40], Loss: 0.0264\n",
      "Epoch [12/50], lter [30/40], Loss: 0.0726\n",
      "Epoch [12/50], lter [40/40], Loss: 0.0279\n",
      "Epoch [13/50], lter [10/40], Loss: 0.0181\n",
      "Epoch [13/50], lter [20/40], Loss: 0.0201\n",
      "Epoch [13/50], lter [30/40], Loss: 0.0540\n",
      "Epoch [13/50], lter [40/40], Loss: 0.0212\n",
      "Epoch [14/50], lter [10/40], Loss: 0.0145\n",
      "Epoch [14/50], lter [20/40], Loss: 0.0156\n",
      "Epoch [14/50], lter [30/40], Loss: 0.0433\n",
      "Epoch [14/50], lter [40/40], Loss: 0.0169\n",
      "Epoch [15/50], lter [10/40], Loss: 0.0119\n",
      "Epoch [15/50], lter [20/40], Loss: 0.0126\n",
      "Epoch [15/50], lter [30/40], Loss: 0.0331\n",
      "Epoch [15/50], lter [40/40], Loss: 0.0139\n",
      "Epoch [16/50], lter [10/40], Loss: 0.0099\n",
      "Epoch [16/50], lter [20/40], Loss: 0.0104\n",
      "Epoch [16/50], lter [30/40], Loss: 0.0279\n",
      "Epoch [16/50], lter [40/40], Loss: 0.0117\n",
      "Epoch [17/50], lter [10/40], Loss: 0.0084\n",
      "Epoch [17/50], lter [20/40], Loss: 0.0089\n",
      "Epoch [17/50], lter [30/40], Loss: 0.0226\n",
      "Epoch [17/50], lter [40/40], Loss: 0.0099\n",
      "Epoch [18/50], lter [10/40], Loss: 0.0073\n",
      "Epoch [18/50], lter [20/40], Loss: 0.0076\n",
      "Epoch [18/50], lter [30/40], Loss: 0.0203\n",
      "Epoch [18/50], lter [40/40], Loss: 0.0086\n",
      "Epoch [19/50], lter [10/40], Loss: 0.0064\n",
      "Epoch [19/50], lter [20/40], Loss: 0.0066\n",
      "Epoch [19/50], lter [30/40], Loss: 0.0163\n",
      "Epoch [19/50], lter [40/40], Loss: 0.0075\n",
      "Epoch [20/50], lter [10/40], Loss: 0.0057\n",
      "Epoch [20/50], lter [20/40], Loss: 0.0058\n",
      "Epoch [20/50], lter [30/40], Loss: 0.0149\n",
      "Epoch [20/50], lter [40/40], Loss: 0.0066\n",
      "Epoch [21/50], lter [10/40], Loss: 0.0051\n",
      "Epoch [21/50], lter [20/40], Loss: 0.0052\n",
      "Epoch [21/50], lter [30/40], Loss: 0.0133\n",
      "Epoch [21/50], lter [40/40], Loss: 0.0059\n",
      "Epoch [22/50], lter [10/40], Loss: 0.0045\n",
      "Epoch [22/50], lter [20/40], Loss: 0.0046\n",
      "Epoch [22/50], lter [30/40], Loss: 0.0119\n",
      "Epoch [22/50], lter [40/40], Loss: 0.0053\n",
      "Epoch [23/50], lter [10/40], Loss: 0.0041\n",
      "Epoch [23/50], lter [20/40], Loss: 0.0042\n",
      "Epoch [23/50], lter [30/40], Loss: 0.0107\n",
      "Epoch [23/50], lter [40/40], Loss: 0.0048\n",
      "Epoch [24/50], lter [10/40], Loss: 0.0037\n",
      "Epoch [24/50], lter [20/40], Loss: 0.0038\n",
      "Epoch [24/50], lter [30/40], Loss: 0.0096\n",
      "Epoch [24/50], lter [40/40], Loss: 0.0043\n",
      "Epoch [25/50], lter [10/40], Loss: 0.0034\n",
      "Epoch [25/50], lter [20/40], Loss: 0.0034\n",
      "Epoch [25/50], lter [30/40], Loss: 0.0088\n",
      "Epoch [25/50], lter [40/40], Loss: 0.0039\n",
      "Epoch [26/50], lter [10/40], Loss: 0.0032\n",
      "Epoch [26/50], lter [20/40], Loss: 0.0031\n",
      "Epoch [26/50], lter [30/40], Loss: 0.0080\n",
      "Epoch [26/50], lter [40/40], Loss: 0.0036\n",
      "Epoch [27/50], lter [10/40], Loss: 0.0029\n",
      "Epoch [27/50], lter [20/40], Loss: 0.0029\n",
      "Epoch [27/50], lter [30/40], Loss: 0.0075\n",
      "Epoch [27/50], lter [40/40], Loss: 0.0034\n",
      "Epoch [28/50], lter [10/40], Loss: 0.0027\n",
      "Epoch [28/50], lter [20/40], Loss: 0.0027\n",
      "Epoch [28/50], lter [30/40], Loss: 0.0069\n",
      "Epoch [28/50], lter [40/40], Loss: 0.0031\n",
      "Epoch [29/50], lter [10/40], Loss: 0.0025\n",
      "Epoch [29/50], lter [20/40], Loss: 0.0024\n",
      "Epoch [29/50], lter [30/40], Loss: 0.0063\n",
      "Epoch [29/50], lter [40/40], Loss: 0.0028\n",
      "Epoch [30/50], lter [10/40], Loss: 0.0023\n",
      "Epoch [30/50], lter [20/40], Loss: 0.0023\n",
      "Epoch [30/50], lter [30/40], Loss: 0.0058\n",
      "Epoch [30/50], lter [40/40], Loss: 0.0026\n",
      "Epoch [31/50], lter [10/40], Loss: 0.0022\n",
      "Epoch [31/50], lter [20/40], Loss: 0.0021\n",
      "Epoch [31/50], lter [30/40], Loss: 0.0054\n",
      "Epoch [31/50], lter [40/40], Loss: 0.0025\n",
      "Epoch [32/50], lter [10/40], Loss: 0.0020\n",
      "Epoch [32/50], lter [20/40], Loss: 0.0019\n",
      "Epoch [32/50], lter [30/40], Loss: 0.0051\n",
      "Epoch [32/50], lter [40/40], Loss: 0.0023\n",
      "Epoch [33/50], lter [10/40], Loss: 0.0019\n",
      "Epoch [33/50], lter [20/40], Loss: 0.0018\n",
      "Epoch [33/50], lter [30/40], Loss: 0.0047\n",
      "Epoch [33/50], lter [40/40], Loss: 0.0022\n",
      "Epoch [34/50], lter [10/40], Loss: 0.0018\n",
      "Epoch [34/50], lter [20/40], Loss: 0.0017\n",
      "Epoch [34/50], lter [30/40], Loss: 0.0045\n",
      "Epoch [34/50], lter [40/40], Loss: 0.0020\n",
      "Epoch [35/50], lter [10/40], Loss: 0.0017\n",
      "Epoch [35/50], lter [20/40], Loss: 0.0016\n",
      "Epoch [35/50], lter [30/40], Loss: 0.0041\n",
      "Epoch [35/50], lter [40/40], Loss: 0.0019\n",
      "Epoch [36/50], lter [10/40], Loss: 0.0016\n",
      "Epoch [36/50], lter [20/40], Loss: 0.0015\n",
      "Epoch [36/50], lter [30/40], Loss: 0.0038\n",
      "Epoch [36/50], lter [40/40], Loss: 0.0018\n",
      "Epoch [37/50], lter [10/40], Loss: 0.0015\n",
      "Epoch [37/50], lter [20/40], Loss: 0.0014\n",
      "Epoch [37/50], lter [30/40], Loss: 0.0036\n",
      "Epoch [37/50], lter [40/40], Loss: 0.0017\n",
      "Epoch [38/50], lter [10/40], Loss: 0.0014\n",
      "Epoch [38/50], lter [20/40], Loss: 0.0013\n",
      "Epoch [38/50], lter [30/40], Loss: 0.0035\n",
      "Epoch [38/50], lter [40/40], Loss: 0.0016\n",
      "Epoch [39/50], lter [10/40], Loss: 0.0013\n",
      "Epoch [39/50], lter [20/40], Loss: 0.0012\n",
      "Epoch [39/50], lter [30/40], Loss: 0.0032\n",
      "Epoch [39/50], lter [40/40], Loss: 0.0015\n",
      "Epoch [40/50], lter [10/40], Loss: 0.0013\n",
      "Epoch [40/50], lter [20/40], Loss: 0.0012\n",
      "Epoch [40/50], lter [30/40], Loss: 0.0031\n",
      "Epoch [40/50], lter [40/40], Loss: 0.0014\n",
      "Epoch [41/50], lter [10/40], Loss: 0.0012\n",
      "Epoch [41/50], lter [20/40], Loss: 0.0011\n",
      "Epoch [41/50], lter [30/40], Loss: 0.0028\n",
      "Epoch [41/50], lter [40/40], Loss: 0.0014\n",
      "Epoch [42/50], lter [10/40], Loss: 0.0011\n",
      "Epoch [42/50], lter [20/40], Loss: 0.0010\n",
      "Epoch [42/50], lter [30/40], Loss: 0.0027\n",
      "Epoch [42/50], lter [40/40], Loss: 0.0013\n",
      "Epoch [43/50], lter [10/40], Loss: 0.0011\n",
      "Epoch [43/50], lter [20/40], Loss: 0.0010\n",
      "Epoch [43/50], lter [30/40], Loss: 0.0025\n",
      "Epoch [43/50], lter [40/40], Loss: 0.0012\n",
      "Epoch [44/50], lter [10/40], Loss: 0.0010\n",
      "Epoch [44/50], lter [20/40], Loss: 0.0009\n",
      "Epoch [44/50], lter [30/40], Loss: 0.0025\n",
      "Epoch [44/50], lter [40/40], Loss: 0.0012\n",
      "Epoch [45/50], lter [10/40], Loss: 0.0010\n",
      "Epoch [45/50], lter [20/40], Loss: 0.0009\n",
      "Epoch [45/50], lter [30/40], Loss: 0.0022\n",
      "Epoch [45/50], lter [40/40], Loss: 0.0011\n",
      "Epoch [46/50], lter [10/40], Loss: 0.0009\n",
      "Epoch [46/50], lter [20/40], Loss: 0.0008\n",
      "Epoch [46/50], lter [30/40], Loss: 0.0022\n",
      "Epoch [46/50], lter [40/40], Loss: 0.0010\n",
      "Epoch [47/50], lter [10/40], Loss: 0.0009\n",
      "Epoch [47/50], lter [20/40], Loss: 0.0008\n",
      "Epoch [47/50], lter [30/40], Loss: 0.0020\n",
      "Epoch [47/50], lter [40/40], Loss: 0.0010\n",
      "Epoch [48/50], lter [10/40], Loss: 0.0008\n",
      "Epoch [48/50], lter [20/40], Loss: 0.0008\n",
      "Epoch [48/50], lter [30/40], Loss: 0.0019\n",
      "Epoch [48/50], lter [40/40], Loss: 0.0010\n",
      "Epoch [49/50], lter [10/40], Loss: 0.0008\n",
      "Epoch [49/50], lter [20/40], Loss: 0.0007\n",
      "Epoch [49/50], lter [30/40], Loss: 0.0018\n",
      "Epoch [49/50], lter [40/40], Loss: 0.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], lter [10/40], Loss: 0.0008\n",
      "Epoch [50/50], lter [20/40], Loss: 0.0007\n",
      "Epoch [50/50], lter [30/40], Loss: 0.0018\n",
      "Epoch [50/50], lter [40/40], Loss: 0.0009\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_batch = len(sound_train) // batch_size\n",
    "    \n",
    "    for i, (batch_images, batch_labels) in enumerate(train_loader):\n",
    "        \n",
    "        X = batch_images.view(-1, 40 * 40)\n",
    "        Y = batch_labels\n",
    "        \n",
    "        pre = model(X)\n",
    "        cost = loss(pre, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch [%d/%d], lter [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, total_batch, cost.item()))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test sound: 12.142857 %\n"
     ]
    }
   ],
   "source": [
    "## model evaluiation\n",
    "        \n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for sound, labels in sound_test:\n",
    "    \n",
    "    sound  = sound.view(-1, 40 * 40)\n",
    "    outputs = model(sound)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += 1\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of test sound: %f %%' % (100 * float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MUTE",
   "language": "python",
   "name": "mute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
